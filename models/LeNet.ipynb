{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes=14):\n",
    "        super(LeNet, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        \n",
    "        # Placeholder for dynamically calculated input features for fc1\n",
    "        self.fc1_input_features = None\n",
    "        \n",
    "        # Fully connected layers (fc1's input size will be adjusted after shape calculation)\n",
    "        self.fc1 = nn.Linear(1, 120)  # Temporary placeholder, will update after shape calculation\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolution layers with pooling and activation\n",
    "        x = nn.ReLU()(self.conv1(x))\n",
    "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
    "        \n",
    "        x = nn.ReLU()(self.conv2(x))\n",
    "        x = nn.MaxPool2d(kernel_size=2, stride=2)(x)\n",
    "        \n",
    "        # Determine the flattened feature size if not already done\n",
    "        if self.fc1_input_features is None:\n",
    "            self.fc1_input_features = x.view(x.size(0), -1).size(1)\n",
    "            self.fc1 = nn.Linear(self.fc1_input_features, 120)  # Adjust fc1 with correct input features\n",
    "            \n",
    "        # Flatten and apply fully connected layers with ReLU\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "# Define your custom dataset directory paths\n",
    "train_dir = '../data/Train'\n",
    "test_dir = '../data/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize images to 32x32 for LeNet\n",
    "    transforms.Grayscale(num_output_channels=1),  # Ensure single-channel grayscale\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),  # Normalize for grayscale images\n",
    "])\n",
    "\n",
    "# Load your custom dataset\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet(num_classes=14)  # Adjusted for 14 output classes\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.5554\n",
      "Epoch [2/20], Loss: 1.0518\n",
      "Epoch [3/20], Loss: 0.9451\n",
      "Epoch [4/20], Loss: 0.8859\n",
      "Epoch [5/20], Loss: 0.8340\n",
      "Epoch [6/20], Loss: 0.7955\n",
      "Epoch [7/20], Loss: 0.7660\n",
      "Epoch [8/20], Loss: 0.7380\n",
      "Epoch [9/20], Loss: 0.7158\n",
      "Epoch [10/20], Loss: 0.6918\n",
      "Epoch [11/20], Loss: 0.6751\n",
      "Epoch [12/20], Loss: 0.6609\n",
      "Epoch [13/20], Loss: 0.6385\n",
      "Epoch [14/20], Loss: 0.6255\n",
      "Epoch [15/20], Loss: 0.6129\n",
      "Epoch [16/20], Loss: 0.5968\n",
      "Epoch [17/20], Loss: 0.5843\n",
      "Epoch [18/20], Loss: 0.5723\n",
      "Epoch [19/20], Loss: 0.5573\n",
      "Epoch [20/20], Loss: 0.5490\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.48%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as lenet_model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"lenet_model.pth\")\n",
    "print(\"Model saved as lenet_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
